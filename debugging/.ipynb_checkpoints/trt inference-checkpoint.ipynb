{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36816998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "onnxModelPath = '/data2/user/sjj995/TensorRT/testing/yolov3-12.onnx'\n",
    "tensorrt_file_name = '/data2/user/sjj995/TensorRT/testing/tiny-yolov3-11.trt'\n",
    "\n",
    "# create builder <- optimization profile, Takes a network in TensorRT and generates an engine that is optimized for the target platform. \n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "trt.init_libnvinfer_plugins(None,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b451fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorrt.tensorrt.Runtime at 0x7f1edcde7fb0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccf76471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/15/2022-02:29:44] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n"
     ]
    }
   ],
   "source": [
    "# trt(engine) model file version = 8.2.4 / tensorrt version = 8.4.1 <-  이렇게 버전 안 맞을때는 안됨\n",
    "# 버전 8.4.1 로 trtexec 다시 해서 모델 만들어서 하면 됨!\n",
    "\n",
    "with open(tensorrt_file_name, 'rb') as f:\n",
    "    engine_data = f.read()\n",
    "\n",
    "engine = engine_data\n",
    "engine = trt_runtime.deserialize_cuda_engine(engine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68b93218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 (1, 3, 256, 256)\n",
      "image_shape (1, 2)\n",
      "yolonms_layer_1:2 (1, 20, 3)\n",
      "yolonms_layer_1:1 (1, 80, 960)\n",
      "yolonms_layer_1 (1, 960, 4)\n"
     ]
    }
   ],
   "source": [
    "for binding in engine:\n",
    "    print(binding,engine.get_binding_shape(binding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2343ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = ['yolonms_layer_1:2','yolonms_layer_1:1','yolonms_layer_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0134c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "(1, 3, 256, 256)\n",
      "image_shape\n",
      "(1, 2)\n",
      "yolonms_layer_1:2\n",
      "(1, 20, 3)\n",
      "yolonms_layer_1:1\n",
      "(1, 80, 960)\n",
      "yolonms_layer_1\n",
      "(1, 960, 4)\n"
     ]
    }
   ],
   "source": [
    "for binding in engine:\n",
    "    if binding in output_data:\n",
    "        print(binding)\n",
    "        print(engine.get_binding_shape(binding))\n",
    "    else:\n",
    "        print(binding)\n",
    "        print(engine.get_binding_shape(binding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8071c634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.num_bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "920a2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5e119b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 256, 256)\n",
      "1\n",
      "196608\n",
      "<class 'numpy.float32'>\n",
      "196608\n",
      "<class 'numpy.ndarray'>\n",
      "139769892604928\n",
      "(1, 2)\n",
      "1\n",
      "2\n",
      "<class 'numpy.float32'>\n",
      "2\n",
      "<class 'numpy.ndarray'>\n",
      "139769891782656\n",
      "(1, 80, 4032)\n",
      "1\n",
      "322560\n",
      "<class 'numpy.float32'>\n",
      "322560\n",
      "<class 'numpy.ndarray'>\n",
      "139769654804480\n",
      "(1, 4032, 4)\n",
      "1\n",
      "16128\n",
      "<class 'numpy.float32'>\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "16128\n",
      "<class 'numpy.ndarray'>\n",
      "139769891783168\n",
      "(20, 3)\n",
      "1\n",
      "60\n",
      "<class 'numpy.int32'>\n",
      "60\n",
      "<class 'numpy.ndarray'>\n",
      "139769891847680\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network cr"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_198000/3418207830.py:8: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
      "  print(engine.max_batch_size)\n",
      "/tmp/ipykernel_198000/3418207830.py:9: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
      "  size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eated with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/14/2022-08:43:15] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "bindings = []\n",
    "stream = cuda.Stream()\n",
    "\n",
    "for binding in engine:\n",
    "    print(engine.get_binding_shape(binding))\n",
    "    print(engine.max_batch_size)\n",
    "    size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "    print(size)\n",
    "    dtype = trt.nptype(engine.get_binding_dtype(binding)) #float 32 안됨\n",
    "    print(dtype)\n",
    "    host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "    print(len(host_mem))\n",
    "    print(type(host_mem))\n",
    "    device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "    print(int(device_mem))\n",
    "    bindings.append(int(device_mem))\n",
    "    # Append to the appropriate list.\n",
    "    if engine.binding_is_input(binding):\n",
    "        inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    else:\n",
    "        outputs.append(HostDeviceMem(host_mem, device_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41d0631d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee47895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host:\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Device:\n",
      "<pycuda._driver.DeviceAllocation object at 0x7f1f03ee4880>\n",
      "Host:\n",
      "[0. 0.]\n",
      "Device:\n",
      "<pycuda._driver.DeviceAllocation object at 0x7f1f03ee4b80>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    print(inputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf9c1a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ca2bf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Host:\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " Device:\n",
       " <pycuda._driver.DeviceAllocation object at 0x7f1f03ee4ca0>,\n",
       " Host:\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " Device:\n",
       " <pycuda._driver.DeviceAllocation object at 0x7f1f03ee4d60>,\n",
       " Host:\n",
       " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
       " Device:\n",
       " <pycuda._driver.DeviceAllocation object at 0x7f1f03ee4ee0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2986bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.5287476  -0.8611883  -1.4576017  -1.5724273  -0.1695489  -1.3563395\n",
      " -0.4535687   0.4312063  -1.0257113   1.2142996  -1.4469191   1.9554813\n",
      " -1.0782161  -1.5831653  -1.2721599   2.2595193  -0.6743571  -1.5215833\n",
      "  0.8629959   0.51497865 -0.38966623]\n",
      "21\n",
      "[ 6.2419553  -0.54691267 -1.3561025  -1.1277876  -0.46587342 -1.3746579\n",
      " -0.7118959   0.21260211 -0.6982413   0.84377265 -0.8377262   1.202004\n",
      " -0.8049982  -0.6954949  -1.2217058   2.3507743  -0.482109   -1.3428153\n",
      "  0.9045931  -0.03164449 -0.05702817]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    print(output.host)\n",
    "    print(len(output.host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff85df99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Host:\n",
       " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       " Device:\n",
       " <pycuda._driver.DeviceAllocation object at 0x7f7fda896e20>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74dffc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140186308922368, 140186308575232]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16dd37f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pycuda._driver.Stream at 0x7f7fda8875e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb86fdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/01/2022-07:38:14] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n"
     ]
    }
   ],
   "source": [
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6045d91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorrt.tensorrt.IExecutionContext at 0x7f80e91b64b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68c2b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "\n",
    "input_data = torch.randn(1,3, 224, 224).to(device)\n",
    "input_data = to_numpy(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a74b0d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.08432246, -0.1058276 , -0.62954396, ...,  0.17907499,\n",
       "          -1.1518197 ,  0.5685717 ],\n",
       "         [-0.07185556,  0.64454466,  0.5704944 , ...,  0.17724264,\n",
       "           1.0886189 , -0.55334747],\n",
       "         [-0.5438037 , -0.75219506, -1.5515512 , ..., -0.88678896,\n",
       "           0.12020984,  0.01209653],\n",
       "         ...,\n",
       "         [-0.3059578 ,  0.33755505,  2.3349192 , ...,  0.66597223,\n",
       "           0.1955215 ,  1.4519386 ],\n",
       "         [-1.1752409 ,  2.2817771 , -0.1215327 , ..., -0.5537824 ,\n",
       "          -0.6690678 , -0.68045217],\n",
       "         [-1.6394802 , -1.424426  ,  2.3718534 , ...,  1.7265902 ,\n",
       "          -0.7573196 ,  1.3781017 ]],\n",
       "\n",
       "        [[ 2.7504265 , -0.47550508, -1.035468  , ..., -0.6198801 ,\n",
       "           2.159974  , -1.6373792 ],\n",
       "         [ 2.1746905 , -1.6749792 , -0.42819417, ..., -0.16059761,\n",
       "           0.9148622 ,  0.35861462],\n",
       "         [ 0.37983966, -0.3215695 , -0.5373664 , ...,  0.08511668,\n",
       "           1.1830088 ,  1.9882578 ],\n",
       "         ...,\n",
       "         [ 2.1545713 , -0.7136638 ,  0.45982885, ..., -1.0315162 ,\n",
       "          -0.3905749 , -0.6832316 ],\n",
       "         [ 1.645461  ,  0.0690968 ,  0.7203505 , ..., -0.71399707,\n",
       "          -0.99240947, -0.7243259 ],\n",
       "         [ 0.4608039 , -0.61536217, -0.7373911 , ...,  1.2132989 ,\n",
       "           0.7820003 , -0.6346681 ]],\n",
       "\n",
       "        [[-0.5184795 ,  0.23591606, -0.6468164 , ..., -1.459963  ,\n",
       "          -0.6856147 , -1.8685337 ],\n",
       "         [-1.3876041 ,  0.69740945, -1.0916966 , ..., -2.053104  ,\n",
       "           0.37061405, -1.0507677 ],\n",
       "         [ 0.24613613, -1.1821215 ,  0.50388   , ...,  0.11130397,\n",
       "           0.35129297,  0.16025768],\n",
       "         ...,\n",
       "         [-1.3792683 , -1.4647214 ,  0.47620434, ..., -0.28331327,\n",
       "           0.06629964, -0.5000145 ],\n",
       "         [ 0.27648294, -0.8364554 ,  1.4141315 , ...,  0.5857904 ,\n",
       "           0.26244822,  0.9052469 ],\n",
       "         [ 1.4450252 , -0.5355767 ,  0.5609143 , ...,  1.0956559 ,\n",
       "           0.9965513 ,  0.1934245 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6e5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n",
    "    # Transfer input data to the GPU.\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bb946ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is generalized for multiple inputs/outputs for full dimension networks.\n",
    "# inputs and outputs are expected to be lists of HostDeviceMem objects.\n",
    "def do_inference_v2(context, bindings, inputs, outputs, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5613e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = [input.host for input in inputs]\n",
    "trt_types = [trt.int32, trt.int32, trt.int32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9dd8a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host:\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Device:\n",
      "<pycuda._driver.DeviceAllocation object at 0x7f7fda896ac0>\n",
      "<class '__main__.HostDeviceMem'>\n",
      "<pycuda._driver.DeviceAllocation object at 0x7f7fda896ac0>\n",
      "150528\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for input in inputs:\n",
    "    print(input)\n",
    "    print(type(input))\n",
    "    print(input.device)\n",
    "    print(len(input.host))\n",
    "    print(type(input.host))\n",
    "    np.copyto(input.host,np.ravel(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fd9d45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorrt.tensorrt.IExecutionContext at 0x7f80e91b64b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af33dcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140186308922368, 140186308575232]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc7a0dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/01/2022-07:44:34] [TRT] [E] 1: [convolutionRunner.cpp::execute::213] Error Code 1: Cask (Cask convolution execution)\n",
      "[07/01/2022-07:44:34] [TRT] [E] 1: [checkMacros.cpp::catchCudaError::278] Error Code 1: Cuda Runtime (invalid resource handle)\n"
     ]
    }
   ],
   "source": [
    "trt_outputs = do_inference_v2(\n",
    "                        context=context,\n",
    "                        bindings=bindings,\n",
    "                        inputs=inputs,\n",
    "                        outputs=outputs,\n",
    "                        stream=stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "afddfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/15/2022-06:05:32] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n",
      "<tensorrt.tensorrt.ICudaEngine object at 0x7f1edcd712b0>\n",
      "[07/15/2022-06:05:32] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.4.0\n",
      "input_1\n",
      "image_shape\n",
      "yolonms_layer_1/ExpandDims_3:0\n",
      "yolonms_layer_1/ExpandDims_1:0\n",
      "yolonms_layer_1/concat_2:0\n",
      "[07/15/2022-06:05:32] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/15/2022-06:05:32] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/15/2022-06:05:32] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/15/2022-06:05:32] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n",
      "[07/15/2022-06:05:32] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_198000/843539126.py:44: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
      "  size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,) into shape (196608,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m input_data \u001b[38;5;241m=\u001b[39m to_numpy(input_data)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# This function is generalized for multiple inputs/outputs for full dimension networks.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# inputs and outputs are expected to be lists of HostDeviceMem objects.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_inference_v2\u001b[39m(context, bindings, inputs, outputs, stream):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Transfer input data to the GPU.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcopyto\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,) into shape (196608,)"
     ]
    }
   ],
   "source": [
    "# 싱글 thread 에서 처리해야함. https://forums.developer.nvidia.com/t/tensorrt-do-inference-error/77055/3\n",
    "\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit # https://forums.developer.nvidia.com/t/logicerror-explicit-context-dependent-failed-invalid-device-context-no-currently-active-context/64149\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#onnxModelPath = '/datadrive/tensorrt/test_onnx'\n",
    "tensorrt_file_name = '/data2/user/sjj995/TensorRT/testing/yolov3-12.trt'\n",
    "#tensorrt_file_name = '/data2/user/sjj995/TensorRT/trt_models/fcn-resnet50-12.trt'\n",
    "\n",
    "# create builder <- optimization profile, Takes a network in TensorRT and generates an engine that is optimized for the target platform. \n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "trt.init_libnvinfer_plugins(None,'')\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "with open(tensorrt_file_name, 'rb') as f:\n",
    "    engine_data = f.read()\n",
    "engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "print(engine)\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "inputs = []\n",
    "outputs = []\n",
    "bindings = []\n",
    "stream = cuda.Stream()\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "for binding in engine:\n",
    "    print(binding)\n",
    "    size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "\n",
    "    dtype = trt.nptype(engine.get_binding_dtype(binding)) #float 32 안됨\n",
    "\n",
    "    host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "\n",
    "    device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "\n",
    "    bindings.append(int(device_mem))\n",
    "    # Append to the appropriate list.\n",
    "    if engine.binding_is_input(binding):\n",
    "        inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    else:\n",
    "        outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "       \n",
    "# for inp in inputs:\n",
    "#     print(inp.host.shape)\n",
    "\n",
    "# for oup in outputs:\n",
    "#     print(oup.host.shape)\n",
    "#     print(oup.device)\n",
    "#     print(stream)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "\n",
    "input_data = torch.randn(1,3, 1, 1).to(device)\n",
    "input_data = to_numpy(input_data)\n",
    "\n",
    "for input in inputs:\n",
    "    np.copyto(input.host,np.ravel(input_data))\n",
    "\n",
    "# This function is generalized for multiple inputs/outputs for full dimension networks.\n",
    "# inputs and outputs are expected to be lists of HostDeviceMem objects.\n",
    "def do_inference_v2(context, bindings, inputs, outputs, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]\n",
    "\n",
    "trt_outputs = do_inference_v2(\n",
    "                        context=context,\n",
    "                        bindings=bindings,\n",
    "                        inputs=inputs,\n",
    "                        outputs=outputs,\n",
    "                        stream=stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7baa06ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cd746b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 125, 13, 13)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b6e874bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stream' object has no attribute 'ptr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [204]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m stream \u001b[38;5;241m=\u001b[39m cuda\u001b[38;5;241m.\u001b[39mStream()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stream' object has no attribute 'ptr'"
     ]
    }
   ],
   "source": [
    "stream = cuda.Stream()\n",
    "stream.ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba465347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 7.5287476 , -0.8611883 , -1.4576017 , -1.5724273 , -0.1695489 ,\n",
       "        -1.3563395 , -0.4535687 ,  0.4312063 , -1.0257113 ,  1.2142996 ,\n",
       "        -1.4469191 ,  1.9554813 , -1.0782161 , -1.5831653 , -1.2721599 ,\n",
       "         2.2595193 , -0.6743571 , -1.5215833 ,  0.8629959 ,  0.51497865,\n",
       "        -0.38966623], dtype=float32),\n",
       " array([ 6.2419553 , -0.54691267, -1.3561025 , -1.1277876 , -0.46587342,\n",
       "        -1.3746579 , -0.7118959 ,  0.21260211, -0.6982413 ,  0.84377265,\n",
       "        -0.8377262 ,  1.202004  , -0.8049982 , -0.6954949 , -1.2217058 ,\n",
       "         2.3507743 , -0.482109  , -1.3428153 ,  0.9045931 , -0.03164449,\n",
       "        -0.05702817], dtype=float32)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bb4292e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.83780634e+00,  1.11267281e+00,  1.33001983e+00,  6.84026659e-01,\n",
       "         1.87992597e+00,  3.03544497e+00,  2.35607076e+00, -4.77835506e-01,\n",
       "        -5.51684141e-01, -1.68703604e+00, -8.21623921e-01,  1.35264337e+00,\n",
       "         1.49944818e+00,  5.92964292e-01,  5.38729012e-01,  1.67636716e+00,\n",
       "         1.02014148e+00,  6.25939906e-01,  3.53781080e+00,  1.53281301e-01,\n",
       "         5.26170552e-01, -1.02307782e-01, -3.66636842e-01,  1.98492572e-01,\n",
       "        -7.22454786e-01, -1.34811616e+00,  2.23169073e-01,  8.66105974e-01,\n",
       "        -7.85946488e-01, -1.21605396e+00, -9.86493647e-01,  1.28093338e+00,\n",
       "        -2.17999625e+00, -4.76416647e-01,  1.35433987e-01, -2.03166342e+00,\n",
       "        -6.85697317e-01, -6.57868236e-02, -1.06951468e-01, -3.93141627e-01,\n",
       "         1.20132041e+00, -9.81076360e-01,  8.66410494e-01, -1.44313490e+00,\n",
       "         2.39185169e-01, -9.36252654e-01,  2.06716061e+00, -2.71192098e+00,\n",
       "        -4.70329762e-01, -2.00526094e+00, -3.69234920e-01, -2.60790348e+00,\n",
       "         4.34934497e-01, -4.58900005e-01, -5.31280816e-01, -2.37489402e-01,\n",
       "        -1.45453882e+00, -2.94936895e+00,  3.69033873e-01, -1.53301612e-01,\n",
       "         5.55688620e-01, -2.58080077e+00, -2.20130563e+00, -2.31538486e+00,\n",
       "        -1.10148382e+00,  1.05559528e+00, -1.47495544e+00, -9.36106503e-01,\n",
       "        -2.00632191e+00,  6.42819583e-01, -1.88612008e+00,  2.45414662e+00,\n",
       "        -1.57798600e+00,  3.37850899e-01, -4.85456467e-01,  1.62950301e+00,\n",
       "         5.22874475e-01,  1.42197239e+00,  3.76264453e+00,  3.68626952e+00,\n",
       "        -3.00776392e-01,  4.51424360e-01,  1.64479539e-02, -4.74974334e-01,\n",
       "         2.91676641e+00,  1.58107197e+00,  2.92435497e-01,  4.80313450e-01,\n",
       "         5.29220030e-02,  1.66596401e+00,  6.76234886e-02, -4.36202846e-02,\n",
       "         1.14471745e+00,  7.46962726e-01,  2.01857281e+00, -2.54900360e+00,\n",
       "         1.08444428e+00, -1.33679104e+00, -1.64401865e+00,  1.39810586e+00,\n",
       "        -1.53970695e+00, -4.08104134e+00, -1.56706989e+00,  2.18245164e-01,\n",
       "        -1.05848050e+00, -2.21386003e+00, -4.66346055e-01,  4.20356035e+00,\n",
       "         1.73286930e-01,  3.28747153e+00,  3.08720899e+00,  4.79708195e+00,\n",
       "         1.43441415e+00,  1.82865655e+00,  3.54665017e+00,  2.05295372e+00,\n",
       "        -1.27109456e+00,  3.03108037e-01,  9.18211102e-01, -1.48457992e+00,\n",
       "        -1.37700784e+00, -1.84554744e+00, -1.53419971e+00, -1.75408947e+00,\n",
       "        -7.18867183e-02, -1.02556980e+00,  1.27598256e-01,  2.13734116e-02,\n",
       "         2.52410918e-01, -1.94624221e+00, -2.66352582e+00, -1.21549118e+00,\n",
       "        -1.03844419e-01, -3.04552726e-02, -7.62020588e-01, -1.34663367e+00,\n",
       "        -1.24297976e+00, -9.79720891e-01,  6.00979507e-01, -1.74346220e+00,\n",
       "        -2.44913054e+00, -3.97406667e-01, -2.66042995e+00, -1.52306128e+00,\n",
       "        -9.50469017e-01,  1.45978880e+00, -1.16854519e-01,  7.20767558e-01,\n",
       "         1.53981848e-02,  8.91466618e-01, -2.96761751e-01, -9.37374830e-01,\n",
       "        -3.53611374e+00, -9.29119110e-01, -7.33788908e-01, -1.20587993e+00,\n",
       "        -4.20309353e+00, -2.39644814e+00, -2.66960478e+00, -2.14044094e+00,\n",
       "        -4.18370533e+00, -1.27079809e+00, -1.62916005e-01, -2.31245518e+00,\n",
       "        -1.21125698e+00, -2.96443772e+00, -2.59565878e+00, -5.69903421e+00,\n",
       "        -1.26209331e+00, -4.17619324e+00, -4.06600380e+00, -3.28814954e-01,\n",
       "        -2.49829578e+00, -2.50684381e+00, -1.18418860e+00, -3.88790679e+00,\n",
       "        -5.00982761e+00, -4.25519419e+00, -7.88651109e-01, -1.59234309e+00,\n",
       "        -1.89558780e+00, -2.55207920e+00, -8.81739557e-01, -1.90186071e+00,\n",
       "        -2.57933784e+00, -8.58642459e-01, -9.57950175e-01, -4.33461249e-01,\n",
       "        -4.24483585e+00, -1.43538129e+00, -2.46559787e+00, -1.78556132e+00,\n",
       "         4.19039845e-01, -1.92441750e+00, -2.91760135e+00,  1.02965856e+00,\n",
       "        -1.40990567e+00, -2.87436080e+00, -2.59688783e+00, -3.56810808e-01,\n",
       "        -2.86560464e+00, -1.16080272e+00, -1.04955494e+00,  7.67462134e-01,\n",
       "        -1.40439212e+00, -3.88239884e+00, -4.17960215e+00, -2.86531425e+00,\n",
       "        -1.51978266e+00, -2.27968311e+00, -2.19750094e+00, -7.80037403e-01,\n",
       "        -2.41089010e+00, -2.05656075e+00, -2.37061238e+00, -2.58305335e+00,\n",
       "        -2.21039009e+00, -3.00193161e-01, -2.47508979e+00, -4.56528693e-01,\n",
       "        -3.85472965e+00, -1.45450366e+00, -4.67962503e+00, -8.55644822e-01,\n",
       "        -3.20956373e+00, -1.39847541e+00, -4.05553722e+00, -1.95297587e+00,\n",
       "        -3.74632645e+00, -1.84386909e+00, -2.40136504e+00, -2.97052217e+00,\n",
       "        -2.35316086e+00, -4.12521076e+00, -2.04959273e+00, -1.75418329e+00,\n",
       "        -2.09721565e+00, -7.39258528e-01, -2.82232714e+00, -3.07975173e+00,\n",
       "        -3.12905502e+00, -3.55485964e+00, -7.39915788e-01, -2.18434358e+00,\n",
       "        -5.77658939e+00,  6.65894210e-01, -3.34050965e+00, -2.52189898e+00,\n",
       "        -1.03376663e+00, -2.10580826e+00, -1.28841984e+00, -7.98530161e-01,\n",
       "        -2.78304577e+00, -1.24949276e+00, -5.60949683e-01, -5.28513765e+00,\n",
       "        -2.92442036e+00, -2.91281652e+00, -1.36698246e+00, -4.49640423e-01,\n",
       "        -2.40160680e+00, -1.66429210e+00, -3.69064975e+00, -1.16893446e+00,\n",
       "        -1.29544628e+00, -5.51905334e-01, -1.31010699e+00, -2.87570715e+00,\n",
       "        -3.63907981e+00, -4.26144981e+00, -3.30388379e+00, -4.32652903e+00,\n",
       "        -1.99905598e+00, -2.40557742e+00, -3.27585340e+00, -2.73552370e+00,\n",
       "        -2.80883908e+00, -4.41588193e-01, -1.53930390e+00,  1.96307003e-01,\n",
       "        -9.07832563e-01,  1.44127452e+00,  1.78277016e+00,  1.03677011e+00,\n",
       "         2.44762373e+00,  1.69605386e+00, -3.22682214e+00, -1.87496984e+00,\n",
       "        -1.68567288e+00, -2.10187912e+00, -3.69129801e+00, -4.50760365e+00,\n",
       "        -2.85581779e+00, -7.96002924e-01, -2.74435353e+00, -2.36700749e+00,\n",
       "        -1.06774139e+00, -3.25394487e+00, -7.78291821e-01, -3.43290478e-01,\n",
       "        -1.66309810e+00,  4.47620153e+00,  5.05083084e-01,  1.54852533e+00,\n",
       "         8.05798352e-01, -1.97276145e-01,  1.53391147e+00,  1.80687463e+00,\n",
       "         2.86436677e+00,  1.14419329e+00,  4.27643871e+00,  4.51352417e-01,\n",
       "         3.94938022e-01,  2.09097290e+00,  9.99049008e-01,  2.20350242e+00,\n",
       "        -6.17185570e-02,  1.40590060e+00,  2.40481615e+00,  9.69135702e-01,\n",
       "         1.10309398e+00, -2.50620198e+00, -3.04057908e+00, -5.84343076e-03,\n",
       "        -1.72062683e+00, -1.30061495e+00, -6.23555720e-01,  1.02920735e+00,\n",
       "         1.00248694e+00,  4.04936612e-01,  5.51331937e-01,  1.00788879e+00,\n",
       "         6.92078650e-01,  1.49821818e+00, -3.14177275e-01, -3.72261137e-01,\n",
       "         2.54989326e-01, -8.25492620e-01, -1.52657712e+00, -3.57220602e+00,\n",
       "        -3.14000106e+00, -4.41990566e+00, -4.27584839e+00, -3.79428768e+00,\n",
       "        -3.45655227e+00, -4.91776133e+00, -4.48592949e+00, -2.87581778e+00,\n",
       "        -3.37151241e+00, -4.13012266e+00, -3.21113563e+00, -2.74407387e+00,\n",
       "        -3.30989432e+00, -1.50879323e+00, -2.22783780e+00, -1.85468090e+00,\n",
       "         1.18306112e+00, -1.07428837e+00,  2.12427273e-01,  1.20281458e-01,\n",
       "        -3.09290409e+00,  1.07330906e+00,  5.84778666e-01,  9.82563198e-01,\n",
       "        -2.78272438e+00, -2.95051146e+00, -2.68568516e+00, -2.11691165e+00,\n",
       "        -3.03037620e+00, -3.20620322e+00, -3.44747138e+00, -4.58611631e+00,\n",
       "        -2.73170304e+00, -1.87820339e+00, -3.49532008e+00, -4.03348207e+00,\n",
       "        -4.04487133e+00, -1.43610299e+00, -3.27213740e+00, -4.05530119e+00,\n",
       "        -2.07748914e+00, -3.18703914e+00, -2.41756797e+00, -1.43511987e+00,\n",
       "        -2.70534348e+00, -4.80263233e+00, -3.07710767e+00, -3.06088233e+00,\n",
       "        -1.89867318e+00, -1.13020885e+00,  8.82297277e-01,  2.85543293e-01,\n",
       "        -3.32113624e-01,  1.11890972e+00, -2.36224818e+00, -3.60450745e-01,\n",
       "        -3.24789196e-01,  5.37527561e-01,  1.66501379e+00,  1.32233694e-01,\n",
       "        -3.00194192e+00, -2.66803056e-01,  1.61287832e+00, -1.24809957e+00,\n",
       "        -5.85004508e-01,  6.19107246e-01, -2.07532024e+00, -2.45340157e+00,\n",
       "        -4.05835676e+00,  2.90439963e+00, -1.80960131e+00,  2.74860239e+00,\n",
       "         2.71811295e+00,  5.43334544e-01,  6.36496544e-01, -6.99439943e-01,\n",
       "         9.72241044e-01,  3.41923833e+00,  4.56232691e+00,  1.88133681e+00,\n",
       "         6.57426596e-01,  1.67007196e+00, -2.89635897e+00, -1.34786141e+00,\n",
       "        -1.25769961e+00,  5.39495230e-01,  2.20403671e+00, -2.96370089e-01,\n",
       "        -3.48134905e-01,  1.45471382e+00, -9.08891201e-01, -1.53600109e+00,\n",
       "         1.12107968e+00,  2.05912757e+00,  1.41618991e+00,  8.12097251e-01,\n",
       "        -8.77188027e-01,  1.69781089e+00,  1.23821819e+00, -3.87154770e+00,\n",
       "         2.48613811e+00,  2.42260456e+00,  7.77598202e-01,  3.30974746e+00,\n",
       "        -2.39533138e+00, -1.04037750e+00,  6.72833347e+00, -4.07501429e-01,\n",
       "        -6.65382817e-02, -2.58128834e+00, -3.37748432e+00,  1.10910165e+00,\n",
       "         1.65137804e+00,  1.12049997e+00, -4.73246098e-01,  3.69229007e+00,\n",
       "         4.72237974e-01,  2.65016198e+00,  3.33719969e+00,  5.38915992e-01,\n",
       "        -5.75542524e-02,  1.54654717e+00,  3.73020911e+00,  1.66669381e+00,\n",
       "         1.39253199e+00, -1.83254886e+00, -3.70274663e+00, -2.06609201e+00,\n",
       "         1.84950888e-01,  4.91319686e-01,  3.74669003e+00, -4.58362520e-01,\n",
       "        -1.04143715e+00,  2.78192616e+00,  8.14305604e-01, -1.07088014e-01,\n",
       "        -4.62829256e+00, -3.42527151e-01,  3.00860763e+00, -2.46532857e-01,\n",
       "         1.75589454e+00,  1.28528166e+00,  1.19955778e+00, -1.56276476e+00,\n",
       "        -6.91193044e-01,  1.01504672e+00, -7.13512301e-02,  1.00925314e+00,\n",
       "         4.24043226e+00,  1.04815614e+00,  4.18039656e+00, -4.64511603e-01,\n",
       "         1.28260112e+00, -4.17301744e-01,  1.12609339e+00,  2.45431751e-01,\n",
       "         5.89239836e-01,  9.48588431e-01,  1.75547314e+00,  3.30778170e+00,\n",
       "        -2.63388824e+00,  1.09273505e+00, -1.47677958e+00,  1.63147855e+00,\n",
       "         2.48477483e+00,  2.20157743e+00,  1.92524707e+00,  1.64537221e-01,\n",
       "         2.25986743e+00, -8.47763181e-01, -1.56334758e+00, -1.07892132e+00,\n",
       "         3.78969121e+00,  7.50914991e-01, -4.22607958e-01,  1.26520288e+00,\n",
       "        -4.19315279e-01,  2.78306675e+00,  4.16308373e-01,  6.46198869e-01,\n",
       "         1.35047242e-01,  9.89782870e-01,  1.19770336e+00,  7.00878859e-01,\n",
       "         1.16352344e+00, -1.34066415e+00, -2.37952575e-01,  1.35811841e+00,\n",
       "         1.81274593e+00, -5.58283806e-01,  2.60848379e+00,  5.08922458e-01,\n",
       "        -7.23142922e-01,  1.09500527e+00,  3.50807476e+00, -4.75148201e+00,\n",
       "        -2.25233257e-01, -3.80584192e+00,  4.16822577e+00,  4.46247816e+00,\n",
       "         1.89675975e+00,  2.92085111e-01,  3.11074471e+00,  6.45131841e-02,\n",
       "        -4.85494167e-01,  1.14722121e+00, -2.95471668e-01, -4.50858879e+00,\n",
       "        -8.87511134e-01,  5.94664383e+00, -6.19661808e-01,  3.49806160e-01,\n",
       "         3.42232561e+00,  4.45426613e-01,  5.13907313e-01, -3.76906604e-01,\n",
       "         2.09625244e+00,  3.40257835e+00,  1.19946611e+00,  1.36774552e+00,\n",
       "         9.01092291e-01, -4.00603145e-01,  3.90149522e+00,  3.04121327e+00,\n",
       "        -2.30600452e+00, -1.20620012e+00, -6.32802010e-01,  2.61875105e+00,\n",
       "        -9.60477889e-01, -3.13064432e+00,  5.79282761e-01, -8.66239727e-01,\n",
       "         2.00526953e+00, -3.89317560e+00,  4.02629757e+00, -3.14288783e+00,\n",
       "        -3.16215014e+00,  1.20644796e+00,  1.14562798e+00,  3.91713709e-01,\n",
       "         1.21893787e+00,  3.15077376e+00, -1.21705484e+00,  8.01470459e-01,\n",
       "         1.80977654e+00,  1.13182676e+00, -3.40112138e+00,  4.33851194e+00,\n",
       "         2.25862885e+00,  1.05946386e+00,  2.64542401e-01,  3.01059985e+00,\n",
       "         8.59753311e-01,  2.43690044e-01, -2.31996942e+00, -4.55734283e-01,\n",
       "         1.84435344e+00,  1.06415069e+00,  2.30662608e+00,  3.27626276e+00,\n",
       "         4.12317085e+00,  8.96637917e-01, -1.39483345e+00, -6.98099422e+00,\n",
       "         1.62147546e+00,  1.21183860e+00,  2.81049132e+00,  1.12073970e+00,\n",
       "         1.78880179e+00, -2.74536562e+00,  1.27291334e+00,  2.40344644e+00,\n",
       "        -2.92474413e+00,  2.93122268e+00, -1.50491929e+00, -4.72901285e-01,\n",
       "         2.22307873e+00,  1.07915771e+00,  4.12389421e+00,  4.21473980e+00,\n",
       "         3.65751457e+00, -1.19206679e+00,  2.56223822e+00,  5.43308640e+00,\n",
       "         5.27849019e-01, -1.81709111e+00,  4.06752443e+00, -4.47010183e+00,\n",
       "        -2.56719470e-01,  2.17897010e+00, -1.88057780e+00,  1.29396307e+00,\n",
       "         3.48229671e+00,  2.53082657e+00, -2.06855559e+00,  1.68931091e+00,\n",
       "         2.31013274e+00,  1.29669940e+00,  7.65093565e-02, -1.27686486e-01,\n",
       "         2.68847132e+00,  8.19633842e-01,  1.05424297e+00,  4.85109210e-01,\n",
       "         6.76936817e+00, -3.30206633e-01,  8.62854362e-01,  1.90863180e+00,\n",
       "         1.22264194e+00,  2.88434768e+00,  2.89868450e+00,  2.10833240e+00,\n",
       "        -2.10268044e+00, -9.57197905e-01, -3.43210483e+00,  1.97720170e+00,\n",
       "        -3.17520785e+00,  3.25197840e+00, -2.07149968e-01,  1.90402210e+00,\n",
       "        -1.20661545e+00, -3.41539454e+00,  1.97524571e+00, -2.23178744e+00,\n",
       "         3.40609622e+00, -2.08117414e+00,  5.30965686e-01, -1.54545203e-01,\n",
       "         1.71450436e+00,  1.73989129e+00, -1.74173152e+00, -4.18342304e+00,\n",
       "        -1.53641844e+00,  3.53219485e+00,  2.76557827e+00, -3.81696486e+00,\n",
       "        -2.19391608e+00,  3.95322943e+00, -1.12698638e+00,  3.30116725e+00,\n",
       "         1.68640184e+00,  3.22865415e+00,  3.10278153e+00,  1.16012537e+00,\n",
       "         3.15235168e-01, -1.83578277e+00, -1.08676219e+00, -2.88080454e+00,\n",
       "         6.77756369e-02, -1.29524469e+00, -7.56619596e+00, -4.12703961e-01,\n",
       "         2.49209309e+00,  1.63280416e+00, -3.89239621e+00,  1.45062721e+00,\n",
       "         4.09183979e+00,  3.44889373e-01, -8.35087538e-01,  1.13972373e-01,\n",
       "         3.53927350e+00,  2.60603762e+00, -1.25772595e+00, -7.58866072e-01,\n",
       "         1.64741814e+00, -2.79444981e+00, -3.85079086e-01,  2.28217530e+00,\n",
       "         1.43715429e+00,  3.29949570e+00,  1.54616380e+00,  3.66459322e+00,\n",
       "         2.16982341e+00,  1.68888831e+00,  1.43224657e+00, -1.04620719e+00,\n",
       "         1.41523039e+00, -1.02071321e+00,  1.48545635e+00,  2.17816305e+00,\n",
       "         2.87636256e+00,  2.98096943e+00,  5.07941818e+00,  1.19467646e-01,\n",
       "        -2.43849850e+00,  4.43922186e+00,  5.29488325e-01,  4.11538887e+00,\n",
       "         2.65239263e+00, -4.66829687e-01, -1.51609576e+00,  2.58469129e+00,\n",
       "        -3.79391760e-02,  2.86962008e+00, -3.82190800e+00,  2.83767295e+00,\n",
       "         3.81655717e+00,  3.11336493e+00,  1.05035996e+00, -3.77240753e+00,\n",
       "         1.72496092e+00,  3.04728699e+00,  1.47047734e+00, -1.65283561e+00,\n",
       "         3.28402305e+00,  2.20159426e-01,  1.53323627e+00,  4.17891026e-01,\n",
       "         8.74476731e-01,  4.49009609e+00,  1.14524245e+00, -2.69258499e+00,\n",
       "         1.19398916e+00,  2.73317122e+00,  3.09750366e+00,  1.00672349e-01,\n",
       "        -5.49661100e-01, -3.16821790e+00, -1.13582420e+00,  2.14112982e-01,\n",
       "         3.85402608e+00,  2.53852677e+00, -1.37235045e+00,  2.89157867e+00,\n",
       "         1.90303922e+00,  1.19054973e+00, -2.79480290e+00,  2.66920948e+00,\n",
       "        -8.37808728e-01,  3.68224645e+00, -2.09694624e+00,  5.95082521e-01,\n",
       "         2.65573144e+00,  2.99264312e+00, -1.01144719e+00,  2.29228839e-01,\n",
       "         8.54321182e-01,  3.39271450e+00,  1.65282607e+00, -1.96248698e+00,\n",
       "        -1.40144360e+00, -7.54295170e-01,  3.35837197e+00,  4.06469631e+00,\n",
       "         4.75030088e+00, -1.21288919e+00,  6.36157095e-01,  7.04261661e-01,\n",
       "        -2.55501056e+00,  1.99178243e+00, -1.48949176e-01,  1.33470345e+00,\n",
       "         2.67737651e+00,  2.16123366e+00,  4.04369164e+00,  1.33066857e+00,\n",
       "        -8.23640600e-02,  5.97488523e-01,  6.91650152e-01,  2.50657511e+00,\n",
       "        -2.31543088e+00,  2.58652520e+00, -1.07418489e+00, -1.08242834e+00,\n",
       "         3.20624208e+00,  5.58364034e-01,  2.06116647e-01,  1.38751030e+00,\n",
       "        -6.14943266e-01,  1.92413568e+00, -1.03090167e+00,  7.79470980e-01,\n",
       "         1.69543791e+00,  3.55856943e+00, -9.26127732e-01,  3.17792964e+00,\n",
       "         1.37793660e+00, -1.94465661e+00,  3.20459843e+00, -6.49261847e-02,\n",
       "        -2.66247869e+00,  1.18605360e-01, -2.46543670e+00,  1.62621725e+00,\n",
       "         2.77393174e+00, -9.96056721e-02,  1.05476701e+00, -8.75918925e-01,\n",
       "         5.01907253e+00, -1.73195076e+00, -8.59233961e-02,  2.84658104e-01,\n",
       "         2.33572215e-01, -9.88660216e-01,  5.29267311e-01,  1.98917401e+00,\n",
       "         3.41064334e-01,  1.14503312e+00,  2.60721594e-01, -6.61219895e-01,\n",
       "         2.26114774e+00,  1.47826684e+00,  1.77452162e-01, -1.07286215e+00,\n",
       "         3.68549538e+00,  4.82566977e+00,  3.44247365e+00, -1.93042767e+00,\n",
       "         4.40349095e-02,  2.41803336e+00,  1.82467118e-01,  3.93127775e+00,\n",
       "         3.46667600e+00, -2.64483750e-01,  3.51112336e-01,  1.97084653e+00,\n",
       "        -4.22421551e+00, -4.25981849e-01,  3.48110938e+00,  1.25322688e+00,\n",
       "        -8.95285130e-01,  2.13128066e+00,  6.64170265e-01, -7.63042331e-01,\n",
       "        -2.87349987e+00, -2.92679596e+00, -1.57718182e+00, -2.47052741e+00,\n",
       "         4.04288483e+00,  5.41218877e-01, -8.12942684e-01, -1.49640620e+00,\n",
       "         2.20874834e+00, -3.11920643e-01, -6.42250443e+00, -3.68961483e-01,\n",
       "         1.98000455e+00, -1.28673816e+00, -1.27499962e+00,  3.65315104e+00,\n",
       "        -5.44667900e-01, -3.23541552e-01,  2.11243486e+00,  4.08395004e+00,\n",
       "         1.81078747e-01,  3.32014275e+00,  4.48702753e-01, -1.20895231e+00,\n",
       "        -1.08145380e+00,  1.56230128e+00, -4.17712021e+00, -3.58924598e-01,\n",
       "         5.06551409e+00,  2.30021286e+00,  3.02753639e+00,  1.39672530e+00,\n",
       "         1.76463366e+00,  1.66101098e+00,  4.32094765e+00,  2.97295213e+00,\n",
       "         1.44271863e+00,  1.33473516e-01,  2.51375651e+00,  1.04464483e+00,\n",
       "         5.72661161e+00,  1.95656931e+00,  1.19304419e+00,  2.17638493e+00,\n",
       "         4.01461124e+00,  1.70512629e+00,  3.79727411e+00,  3.29925895e+00,\n",
       "        -1.92411113e+00, -3.18852425e-01, -2.33128548e+00, -2.08880758e+00,\n",
       "         1.44048047e+00, -4.83866334e-01,  3.75146896e-01,  1.70874739e+00,\n",
       "         2.22363281e+00,  2.78880143e+00,  8.50193441e-01, -1.02250922e+00,\n",
       "        -5.84753275e-01,  6.93817258e-01, -1.96138763e+00, -1.74855816e+00,\n",
       "         9.28760588e-01,  3.53761268e+00,  8.72095048e-01,  2.37323806e-01,\n",
       "         8.25572431e-01,  1.46584260e+00,  6.11380458e-01,  1.30661881e+00,\n",
       "         3.78518343e-01,  2.59596848e+00,  1.18762684e+00,  1.98307776e+00,\n",
       "         4.43194956e-01, -1.09827065e+00, -2.49640852e-01,  1.20137787e+00,\n",
       "        -2.07344508e+00,  2.52047944e+00, -2.08259368e+00,  2.00627014e-01,\n",
       "         4.08840179e+00,  3.22673392e+00,  4.53736210e+00,  4.48152542e+00,\n",
       "         1.31446660e+00,  3.48053908e+00,  4.03765869e+00,  8.75627160e-01,\n",
       "        -1.61861420e+00,  1.35890090e+00,  9.19820845e-01, -9.40940738e-01,\n",
       "         1.10114522e-01,  3.29001927e+00,  1.53758317e-01, -2.02212512e-01,\n",
       "        -4.77011085e-01, -1.87299120e+00,  2.53198457e+00,  2.69792891e+00,\n",
       "         4.26362228e+00,  3.90433669e-01, -1.16177642e+00,  5.05762291e+00,\n",
       "        -1.07540798e+00,  1.26738000e+00,  1.32142198e+00,  2.48615980e-01,\n",
       "         1.98853016e-02,  2.48771429e+00,  1.37371087e+00, -1.97153139e+00,\n",
       "         5.02184093e-01, -9.11438048e-01, -3.26772779e-01,  2.01130772e+00,\n",
       "         1.67458102e-01,  9.67054009e-01, -3.07071805e+00,  6.90172136e-01,\n",
       "         3.83306444e-01,  1.41413078e-01,  2.00164482e-01, -7.92527258e-01,\n",
       "        -1.18276322e+00, -4.00994730e+00, -3.91428828e+00, -2.31439805e+00,\n",
       "        -2.90848184e+00, -1.11767685e+00,  8.97372782e-01,  2.32099962e+00],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "616402d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datadrive/tensorrt/mobilenet.trt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m trt_runtime \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mRuntime(TRT_LOGGER)\n\u001b[1;32m     16\u001b[0m EXPLICIT_BATCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m (\u001b[38;5;28mint\u001b[39m)(trt\u001b[38;5;241m.\u001b[39mNetworkDefinitionCreationFlag\u001b[38;5;241m.\u001b[39mEXPLICIT_BATCH)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensorrt_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     19\u001b[0m     engine_data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     20\u001b[0m engine \u001b[38;5;241m=\u001b[39m trt_runtime\u001b[38;5;241m.\u001b[39mdeserialize_cuda_engine(engine_data)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datadrive/tensorrt/mobilenet.trt'"
     ]
    }
   ],
   "source": [
    "# 싱글 thread 에서 처리해야함. https://forums.developer.nvidia.com/t/tensorrt-do-inference-error/77055/3\n",
    "\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit # https://forums.developer.nvidia.com/t/logicerror-explicit-context-dependent-failed-invalid-device-context-no-currently-active-context/64149\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#onnxModelPath = '/datadrive/tensorrt/onnx_models/mobilenetv2-7.onnx'\n",
    "tensorrt_file_name = '/datadrive/tensorrt/mobilenet.trt'\n",
    "\n",
    "# create builder <- optimization profile, Takes a network in TensorRT and generates an engine that is optimized for the target platform. \n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "with open(tensorrt_file_name, 'rb') as f:\n",
    "    engine_data = f.read()\n",
    "engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "inputs = []\n",
    "outputs = []\n",
    "bindings = []\n",
    "stream = cuda.Stream()\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "for binding in engine:\n",
    "    print(engine.get_binding_shape(binding))\n",
    "    print(engine.max_batch_size)\n",
    "    size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "    print(size)\n",
    "    dtype = trt.nptype(engine.get_binding_dtype(binding)) #float 32 안됨\n",
    "    print(dtype)\n",
    "    host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "    print(len(host_mem))\n",
    "    device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "    print(int(device_mem))\n",
    "    bindings.append(int(device_mem))\n",
    "    # Append to the appropriate list.\n",
    "    if engine.binding_is_input(binding):\n",
    "        inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    else:\n",
    "        outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "       \n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "\n",
    "input_data = torch.randn(1,3, 224, 224).to(device)\n",
    "input_data = to_numpy(input_data)\n",
    "\n",
    "for input in inputs:\n",
    "    np.copyto(input.host,np.ravel(input_data))\n",
    "\n",
    "# This function is generalized for multiple inputs/outputs for full dimension networks.\n",
    "# inputs and outputs are expected to be lists of HostDeviceMem objects.\n",
    "def do_inference_v2(context, bindings, inputs, outputs, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]\n",
    "\n",
    "trt_outputs = do_inference_v2(\n",
    "                        context=context,\n",
    "                        bindings=bindings,\n",
    "                        inputs=inputs,\n",
    "                        outputs=outputs,\n",
    "                        stream=stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 싱글 thread 에서 처리해야함. https://forums.developer.nvidia.com/t/tensorrt-do-inference-error/77055/3\n",
    "import time\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit # https://forums.developer.nvidia.com/t/logicerror-explicit-context-dependent-failed-invalid-device-context-no-currently-active-context/64149\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#onnxModelPath = '/datadrive/tensorrt/onnx_models/mobilenetv2-7.onnx'\n",
    "tensorrt_file_name = '/data2/user/sjj995/TensorRT/trt_models/'\n",
    "\n",
    "# create builder <- optimization profile, Takes a network in TensorRT and generates an engine that is optimized for the target platform. \n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "with open(tensorrt_file_name, 'rb') as f:\n",
    "    engine_data = f.read()\n",
    "engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "inputs = []\n",
    "outputs = []\n",
    "bindings = []\n",
    "stream = cuda.Stream()\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "for binding in engine:\n",
    "    print(engine.get_binding_shape(binding))\n",
    "    print(engine.max_batch_size)\n",
    "    size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "    print(size)\n",
    "    dtype = trt.nptype(engine.get_binding_dtype(binding)) #float 32 안됨\n",
    "    print(dtype)\n",
    "    host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "    print(len(host_mem))\n",
    "    device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "    print(int(device_mem))\n",
    "    bindings.append(int(device_mem))\n",
    "    # Append to the appropriate list.\n",
    "    if engine.binding_is_input(binding):\n",
    "        inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    else:\n",
    "        outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "       \n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "def preprocess(img):\n",
    "    model_image_size = (416, 416)\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    return image_data\n",
    "\n",
    "image = Image.open(\"/data2/user/sjj995/TensorRT/bicycle.jpg\")\n",
    "image_data = preprocess(image)\n",
    "image_size = np.array([image.size[1], image.size[0]], dtype=np.float32).reshape(1, 2)\n",
    "input_data = [image_data,image_size]\n",
    "\n",
    "\n",
    "for input in inputs:\n",
    "    np.copyto(input.host,np.ravel(input_data))\n",
    "\n",
    "# This function is generalized for multiple inputs/outputs for full dimension networks.\n",
    "# inputs and outputs are expected to be lists of HostDeviceMem objects.\n",
    "def do_inference_v2(context, bindings, inputs, outputs, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]\n",
    "\n",
    "trt_outputs = do_inference_v2(\n",
    "                        context=context,\n",
    "                        bindings=bindings,\n",
    "                        inputs=inputs,\n",
    "                        outputs=outputs,\n",
    "                        stream=stream)\n",
    "\n",
    "\n",
    "\n",
    "session = onnxruntime.InferenceSession(\"/data2/user/sjj995/TensorRT/onnx_models/yolov3-12.onnx\")\n",
    "inname = [input.name for input in session.get_inputs()]\n",
    "outname = [output.name for output in session.get_outputs()]\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "def preprocess(img):\n",
    "    model_image_size = (416, 416)\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    return image_data\n",
    "\n",
    "def get_prediction(image_data, image_size):\n",
    "    input = {\n",
    "        inname[0]: image_data,\n",
    "        inname[1]: image_size\n",
    "    }\n",
    "    t0 = time.time()\n",
    "    boxes, scores, indices = session.run(outname, input)\n",
    "    print(\"Predict Time: %ss\" % (time.time() - t0))\n",
    "    out_boxes, out_scores, out_classes = [], [], []\n",
    "    print(indices)\n",
    "    print(indices.shape)\n",
    "    for idx_ in indices:\n",
    "        out_classes.append(idx_[1])\n",
    "        out_scores.append(scores[tuple(idx_)])\n",
    "        idx_1 = (idx_[0], idx_[2])\n",
    "        out_boxes.append(boxes[idx_1])\n",
    "    return out_boxes, out_scores, out_classes\n",
    "\n",
    "label =[\"person\",\"bicycle\",\"car\",\"motorbike\",\"aeroplane\",\"bus\",\"train\",\"truck\",\"boat\",\n",
    "    \"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\n",
    "    \"dog\",\"horse\",\"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\"giraffe\",\"backpack\",\"umbrella\",\n",
    "    \"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\"baseball bat\",\n",
    "    \"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"wine glass\",\"cup\",\"fork\",\n",
    "    \"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\n",
    "    \"pizza\",\"donut\",\"cake\",\"chair\",\"sofa\",\"pottedplant\",\"bed\",\"diningtable\",\"toilet\",\"tvmonitor\",\n",
    "    \"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\"microwave\",\"oven\",\"toaster\",\"sink\",\n",
    "    \"refrigerator\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\"hair drier\",\"toothbrush\"]\n",
    "\n",
    "image = Image.open(\"/data2/user/sjj995/TensorRT/bicycle.jpg\")\n",
    "image_data = preprocess(image)\n",
    "image_size = np.array([image.size[1], image.size[0]], dtype=np.float32).reshape(1, 2)\n",
    "out_boxes, out_scores, out_classes = get_prediction(image_data, image_size)\n",
    "out_boxes = np.array(out_boxes).tolist()\n",
    "out_scores = np.array(out_scores).tolist()\n",
    "out_classes = np.array(out_classes).tolist()\n",
    "\n",
    "for i, c in reversed(list(enumerate(out_classes))):\n",
    "    print(\"box:\", out_boxes[i])\n",
    "    print(\"score:\", out_scores[i],\",\", label[c])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
