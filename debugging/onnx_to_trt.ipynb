{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f842b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "\n",
    "tensorrt_file_name='jupyter_yolo.trt'\n",
    "\n",
    "class ModelData(object):\n",
    "    MODEL_PATH = \"/data2/user/sjj995/TensorRT/test/ssd_mobilenet_v1_10.onnx\"\n",
    "    INPUT_SHAPE = (1,127, 127)\n",
    "    # We can convert TensorRT data types to numpy types with trt.nptype()\n",
    "    DTYPE = torch.float32\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "\n",
    "def GiB(val):\n",
    "    return val * 1 << 30\n",
    "    \n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# The Onnx path is used for Onnx models.\n",
    "def build_engine_onnx(model_file):\n",
    "    \n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    profile = builder.create_optimization_profile()\n",
    "    #print(profile.get_shape_input())\n",
    "    #profile.set_shape(\"image_shape\", (1, 2),(1, 2),(1, 2))\n",
    "    #profile.set_shape(\"input_1\", (1,3, 416, 416),(1,3, 416, 416),(1,3, 416, 416))\n",
    "    profile.set_shape(\"image_tensor:0\", (1,127, 127),(1,127, 127),(1,127, 127))\n",
    "    #print(profile.get_shape_input)\n",
    "    network = builder.create_network(EXPLICIT_BATCH)\n",
    "    \n",
    "    config = builder.create_builder_config()\n",
    "    config.add_optimization_profile(profile)\n",
    "    config.max_workspace_size = 8 << 30\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    parser_error = trt.ParserError\n",
    "    #Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "    with open(model_file, \"rb\") as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            print(\"ERROR: Failed to parse the ONNX file.\")\n",
    "            for error in range(parser.num_errors):\n",
    "                print(parser.get_error(error).node())\n",
    "                error_node = parser.get_error(error).node()\n",
    "                onnx_model_detailed = onnx.load(model_file)\n",
    "#                 for node_num,node_info in enumerate(onnx_model_detailed.graph.node):\n",
    "#                     if node_num == error_node:\n",
    "#                         print(node_num,node_info.op_type)\n",
    "        #print(parser.num_errors)\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    return builder.build_engine(network, config=config)\n",
    "    #return 0\n",
    "\n",
    "onnx2 = ModelData()\n",
    "print(onnx2.MODEL_PATH)\n",
    "trt_engine = build_engine_onnx(onnx2.MODEL_PATH) # IcudaEngine \n",
    "\n",
    "#print(trt_engine)\n",
    "# buf = trt_engine.serialize() # trt engine 으로  serialized\n",
    "# with open(tensorrt_file_name,'wb') as f:\n",
    "#     f.write(buf)\n",
    "\n",
    "# print(trt_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f271400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import torch\n",
    "import onnx\n",
    "from onnx import helper\n",
    "\n",
    "tensorrt_file_name='jupyter_yolo.trt'\n",
    "\n",
    "class ModelData(object):\n",
    "    MODEL_PATH = \"/data2/user/sjj995/TensorRT/verified/verified_onnx_models/zfnet512-12.onnx\"\n",
    "    INPUT_SHAPE = (1,3, 224,224)\n",
    "    # We can convert TensorRT data types to numpy types with trt.nptype()\n",
    "    DTYPE = torch.float32\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "\n",
    "def GiB(val):\n",
    "    return val * 1 << 30\n",
    "    \n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# The Onnx path is used for Onnx models.\n",
    "def build_engine_onnx(model_file):\n",
    "    \n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    profile = builder.create_optimization_profile()\n",
    "    #print(profile.get_shape_input())\n",
    "    #profile.set_shape(\"image_shape\", (1, 2),(1, 2),(1, 2))\n",
    "    #profile.set_shape(\"input_1\", (1,3, 416, 416),(1,3, 416, 416),(1,3, 416, 416))\n",
    "    profile.set_shape(\"image\",(1,3, 224,224),(1,3, 224,224),(1,3, 224,224))\n",
    "    #print(profile.get_shape_input)\n",
    "    network = builder.create_network(EXPLICIT_BATCH)\n",
    "    \n",
    "    config = builder.create_builder_config()\n",
    "    config.add_optimization_profile(profile)\n",
    "    config.max_workspace_size = 8 << 30\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    parser_error = trt.ParserError\n",
    "    #Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "    with open(model_file, \"rb\") as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            print(\"ERROR: Failed to parse the ONNX file.\")\n",
    "            print('hi')\n",
    "        for error in range(parser.num_errors):\n",
    "            print(parser.get_error(error).node())\n",
    "        print(parser.num_errors)\n",
    "        return None\n",
    "            \n",
    "    return builder.build_engine(network, config=config)\n",
    "    #return 0\n",
    "\n",
    "onnx = ModelData()\n",
    "\n",
    "trt_engine = build_engine_onnx(onnx.MODEL_PATH) # IcudaEngine \n",
    "#print(trt_engine)\n",
    "# buf = trt_engine.serialize() # trt engine 으로  serialized\n",
    "# with open(tensorrt_file_name,'wb') as f:\n",
    "#     f.write(buf)\n",
    "\n",
    "# print(trt_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c11edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "\n",
    "model_info = \"/data2/user/sjj995/TensorRT/verified/unsupported/MaskRCNN-10.onnx\"\n",
    "onnx_model = onnx.load(model_info)\n",
    "\n",
    "for n in onnx_model.graph.node:\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb83f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx 모델의 정보를 layer 이름 : layer값 기준으로 저장합니다.\n",
    "onnx_layers = dict()\n",
    "for layer in onnx_model.graph.initializer:\n",
    "    onnx_layers[layer.name] = numpy_helper.to_array(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4952259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "onnx_model='/datadrive/tensorrt/onnx_models/mobilenetv2-12.onnx'\n",
    "\n",
    "tensort_file_name = Path(onnx_model).stem+'.trt'\n",
    "tensort_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx = ModelData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_engine_onnx(onnx.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0829143",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 << 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "8 << 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = ['batch_size', 3, 224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95595aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(1 if dim == 'batch_size' else dim for dim in list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = [\"input\",\"input_1\",\"input_2\"]\n",
    "input_shape = ['']\n",
    "temp_d = {\"shufflenet-false\": [\n",
    "        input_name,\n",
    "        \"[1, 3, 224, 224]\",\n",
    "        \"output\",\n",
    "        \"[1, 1000]\",\n",
    "        1.0,\n",
    "        0.986,\n",
    "        4.7683716e-06,\n",
    "        \"(0, 210)\"\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7795b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"test.json\",'w',encoding='utf-8') as f:\n",
    "    json.dump(temp_d,f,indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd337d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority={1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bool(priority):\n",
    "    print('hello')\n",
    "else:\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "t1 = np.arange(1,101).reshape(1,10,10)\n",
    "t2 = np.arange(1,201,2).reshape(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d563ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadde4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pos = np.where(abs(t1-t2) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple([temp_pos[j][0] for j in range(len(temp_pos))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6a0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46db9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f540bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(t1-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2[0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f72213",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pos=['(array([0]), array([2]), array([160]), array([214]))']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(0.000584608843537415,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "\n",
    "tensorrt_file_name='jupyter_yolo.trt'\n",
    "\n",
    "class ModelData(object):\n",
    "    MODEL_PATH = \"/data2/user/sjj995/TensorRT/temp2/vgg16-7.onnx\"\n",
    "    INPUT_SHAPE = (1,3,224,224)\n",
    "    # We can convert TensorRT data types to numpy types with trt.nptype()\n",
    "    DTYPE = torch.float32\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "\n",
    "def GiB(val):\n",
    "    return val * 1 << 30\n",
    "    \n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# The Onnx path is used for Onnx models.\n",
    "def build_engine_onnx(model_file):\n",
    "    \n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    profile = builder.create_optimization_profile()\n",
    "    #print(profile.get_shape_input())\n",
    "    #profile.set_shape(\"image_shape\", (1, 2),(1, 2),(1, 2))\n",
    "    #profile.set_shape(\"input_1\", (1,3, 416, 416),(1,3, 416, 416),(1,3, 416, 416))\n",
    "    profile.set_shape(\"data\", (1,3,224,224),(1,3,224,224),(1,3,224,224))\n",
    "    #print(profile.get_shape_input)\n",
    "    network = builder.create_network(EXPLICIT_BATCH)\n",
    "    \n",
    "    config = builder.create_builder_config()\n",
    "    config.add_optimization_profile(profile)\n",
    "    config.max_workspace_size = 8 << 30\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    parser_error = trt.ParserError\n",
    "    #Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "    with open(model_file, \"rb\") as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            print(\"ERROR: Failed to parse the ONNX file.\")\n",
    "            for error in range(parser.num_errors):\n",
    "                print(parser.get_error(error).node())\n",
    "                error_node = parser.get_error(error).node()\n",
    "                onnx_model_detailed = onnx.load(model_file)\n",
    "#                 for node_num,node_info in enumerate(onnx_model_detailed.graph.node):\n",
    "#                     if node_num == error_node:\n",
    "#                         print(node_num,node_info.op_type)\n",
    "        print(\"TensorRT Layers 정보 : \",network.num_layers)\n",
    "        for i in range(network.num_layers):\n",
    "            for j in range(network.get_layer(i).num_outputs):\n",
    "                print(network.get_layer(i).name,network.get_layer(i).get_output_type(j),network.get_layer(i).get_output(j).shape)\n",
    "        return None\n",
    "            \n",
    "    return builder.build_engine(network, config=config)\n",
    "    #return 0\n",
    "\n",
    "onnx2 = ModelData()\n",
    "print(onnx2.MODEL_PATH)\n",
    "trt_engine = build_engine_onnx(onnx2.MODEL_PATH) # IcudaEngine \n",
    "\n",
    "#print(trt_engine)\n",
    "# buf = trt_engine.serialize() # trt engine 으로  serialized\n",
    "# with open(tensorrt_file_name,'wb') as f:\n",
    "#     f.write(buf)\n",
    "\n",
    "# print(trt_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f187e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/user/sjj995/TensorRT/temp2/FasterRCNN-12.onnx\n",
      "2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1864/1215060321.py:39: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 8 << 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/202{'TopK': [1, ['2088']], 'NonZero': [98, ['811', '794', '750', '733', '689', '672', '628', '611', '567', '550', '2403', '2485', '2419', '2513', '2435', '2541', '2451', '2569', '6323', '6279', '6235', '6191', '6147', '6103', '6059', '6015', '5971', '5927', '5883', '5839', '5795', '5751', '5707', '5663', '5619', '5575', '5531', '5487', '5443', '5399', '5355', '5311', '5267', '5223', '5179', '5135', '5091', '5047', '5003', '4959', '4915', '4871', '4827', '4783', '4739', '4695', '4651', '4607', '4563', '4519', '4475', '4431', '4387', '4343', '4299', '4255', '4211', '4167', '4123', '4079', '4035', '3991', '3947', '3903', '3859', '3815', '3771', '3727', '3683', '3639', '3595', '3551', '3507', '3463', '3419', '3375', '3331', '3287', '3243', '3199', '3155', '3111', '3067', '3023', '2979', '2935', '2891', '2847']], 'NonMaxSuppression': [85, ['2311', '2016', '1721', '1426', '1131', '6342', '6298', '6254', '6210', '6166', '6122', '6078', '6034', '5990', '5946', '5902', '5858', '5814', '5770', '5726', '5682', '5638', '5594', '5550', '5506', '5462', '5418', '5374', '5330', '5286', '5242', '5198', '5154', '5110', '5066', '5022', '4978', '4934', '4890', '4846', '4802', '4758', '4714', '4670', '4626', '4582', '4538', '4494', '4450', '4406', '4362', '4318', '4274', '4230', '4186', '4142', '4098', '4054', '4010', '3966', '3922', '3878', '3834', '3790', '3746', '3702', '3658', '3614', '3570', '3526', '3482', '3438', '3394', '3350', '3306', '3262', '3218', '3174', '3130', '3086', '3042', '2998', '2954', '2910', '2866']], 'RoiAlign': [4, ['2414', '2430', '2446', '2462']]}\n",
      "2-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:24:29] [TRT] [E] ImporterContext.cpp:93: Constant layer: 2056_1193 can be a duplicate of: 2056\n",
      "[07/26/2022-08:24:29] [TRT] [E] ImporterContext.cpp:93: Constant layer: 2037_1194 can be a duplicate of: 2037\n",
      "[07/26/2022-08:24:29] [TRT] [E] 4: [network.cpp::validate::2671] Error Code 4: Internal Error (Network must have at least one output)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1864/1215060321.py:82: DeprecationWarning: Use build_serialized_network instead.\n",
      "  return builder.build_engine(network, config=config)\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "\n",
    "tensorrt_file_name='jupyter_faster.trt'\n",
    "\n",
    "class ModelData(object):\n",
    "    MODEL_PATH = \"/data2/user/sjj995/TensorRT/temp2/FasterRCNN-12.onnx\"\n",
    "    INPUT_SHAPE = (1,3,224,224)\n",
    "    # We can convert TensorRT data types to numpy types with trt.nptype()\n",
    "    DTYPE = torch.float32\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "\n",
    "def GiB(val):\n",
    "    return val * 1 << 30\n",
    "    \n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# The Onnx path is used for Onnx models.\n",
    "def build_engine_onnx(model_file):\n",
    "    \n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    profile = builder.create_optimization_profile()\n",
    "    #print(profile.get_shape_input())\n",
    "    #profile.set_shape(\"image_shape\", (1, 2),(1, 2),(1, 2))\n",
    "    #profile.set_shape(\"input_1\", (1,3, 416, 416),(1,3, 416, 416),(1,3, 416, 416))\n",
    "    profile.set_shape(\"data\", (1,3,224,224),(1,3,224,224),(1,3,224,224))\n",
    "    #print(profile.get_shape_input)\n",
    "    network = builder.create_network(EXPLICIT_BATCH)\n",
    "    \n",
    "    config = builder.create_builder_config()\n",
    "    config.add_optimization_profile(profile)\n",
    "    config.max_workspace_size = 8 << 30\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    parser_error = trt.ParserError\n",
    "    #Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "    \n",
    "    \n",
    "    \n",
    "    onnx_model_detailed = onnx.load(model_file)\n",
    "    print(len(onnx_model_detailed.graph.node))\n",
    "    \n",
    "    trt_support_node = []\n",
    "#     unsupported_op_type = [0 for _ in range(len(onnx_model_detailed.graph.node))]\n",
    "#     unsupported_node_name = [None for _ in range(len(onnx_model_detailed.graph.node))]\n",
    "    unsupported_op = {}\n",
    "        \n",
    "    #print(unsupported_node)\n",
    "    with open(model_file, \"rb\") as model:\n",
    "#         if parser.parse(model.read()):\n",
    "        #print(\"ERROR: Failed to parse the ONNX file.\")\n",
    "        chk_support = parser.supports_model(model.read())\n",
    "        #print(chk_support)\n",
    "        for subgraph in chk_support[1]:\n",
    "            #print('subgraph',subgraph[0])\n",
    "            for idx in subgraph[0]:\n",
    "                #print(idx)\n",
    "                trt_support_node.append(idx)\n",
    "            #trt_support_node = subgraph[0]\n",
    "\n",
    "    for node_num,node_info in enumerate(onnx_model_detailed.graph.node):\n",
    "        if node_num not in trt_support_node:\n",
    "            #print(node_num,node_info.op_type)\n",
    "            if node_info.op_type not in unsupported_op:\n",
    "                unsupported_op[node_info.op_type] = [1,[node_info.name]]\n",
    "            else:\n",
    "                unsupported_op[node_info.op_type][0] += 1\n",
    "                unsupported_op[node_info.op_type][1].append(node_info.name)\n",
    "#             unsupported_node_name[node_num] = node_info.name\n",
    "#             unsupported_op_type[node_num] = node_info.op_type\n",
    "    \n",
    "    print(unsupported_op)\n",
    "#     op_list = []\n",
    "#     for op in list(set(unsupported_op_type))[1:]:\n",
    "#         op_list.append(unsupported_op_type.count(op)\n",
    "    return builder.build_engine(network, config=config)\n",
    "\n",
    "onnx2 = ModelData()\n",
    "print(onnx2.MODEL_PATH)\n",
    "trt_engine = build_engine_onnx(onnx2.MODEL_PATH) # IcudaEngine \n",
    "print(trt_engine)\n",
    "\n",
    "# buf = trt_engine.serialize() # trt engine 으로  serialized\n",
    "# with open(tensorrt_file_name,'wb') as f:\n",
    "#     f.write(buf)\n",
    "\n",
    "# print(trt_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4300f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/user/sjj995/TensorRT/temp2/FasterRCNN-12.onnx\n",
      "2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1864/3206974603.py:39: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 8 << 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "여기2 149\n",
      "0\n",
      "여기 149\n",
      "149\n",
      "175\n",
      "188\n",
      "264\n",
      "321\n",
      "334\n",
      "410\n",
      "484\n",
      "497\n",
      "573\n",
      "647\n",
      "660\n",
      "736\n",
      "810\n",
      "823\n",
      "899\n",
      "940\n",
      "952\n",
      "962\n",
      "984\n",
      "992\n",
      "1002\n",
      "1013\n",
      "1021\n",
      "1031\n",
      "1042\n",
      "1050\n",
      "1060\n",
      "1090\n",
      "1169\n",
      "1176\n",
      "1185\n",
      "1192\n",
      "1201\n",
      "1208\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outs1217\n",
      "1224\n",
      "1233\n",
      "1240\n",
      "1249\n",
      "1256\n",
      "1265\n",
      "1272\n",
      "1281\n",
      "1288\n",
      "1297\n",
      "1304\n",
      "1313\n",
      "1320\n",
      "1329\n",
      "1336\n",
      "1345\n",
      "1352\n",
      "1361\n",
      "1368\n",
      "1377\n",
      "1384\n",
      "1393\n",
      "1400\n",
      "1409\n",
      "1416\n",
      "1425\n",
      "1432\n",
      "1441\n",
      "1448\n",
      "1457\n",
      "1464\n",
      "1473\n",
      "1480\n",
      "1489\n",
      "1496\n",
      "1505\n",
      "1512\n",
      "1521\n",
      "1528\n",
      "1537\n",
      "1544\n",
      "1553\n",
      "1560\n",
      "1569\n",
      "1576\n",
      "1585\n",
      "1592\n",
      "1601\n",
      "1608\n",
      "1617\n",
      "1624\n",
      "1633\n",
      "1640\n",
      "1649\n",
      "1656\n",
      "1665\n",
      "1672\n",
      "1681\n",
      "1688\n",
      "1697\n",
      "1704\n",
      "1713\n",
      "1720\n",
      "1729\n",
      "1736\n",
      "ide the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_util1745\n",
      "1752\n",
      "1761\n",
      "1768\n",
      "1777\n",
      "1784\n",
      "1793\n",
      "1800\n",
      "1809\n",
      "1816\n",
      "1825\n",
      "1832\n",
      "1841\n",
      "1848\n",
      "1857\n",
      "1864\n",
      "1873\n",
      "1880\n",
      "1889\n",
      "1896\n",
      "1905\n",
      "1912\n",
      "1921\n",
      "1928\n",
      "1937\n",
      "1944\n",
      "1953\n",
      "1960\n",
      "1969\n",
      "1976\n",
      "1985\n",
      "1992\n",
      "2001\n",
      "2008\n",
      "2017\n",
      "2024\n",
      "2033\n",
      "2040\n",
      "2049\n",
      "2056\n",
      "2065\n",
      "2072\n",
      "2081\n",
      "2088\n",
      "2097\n",
      "2104\n",
      "2113\n",
      "2120\n",
      "2129\n",
      "2136\n",
      "2145\n",
      "2152\n",
      "2161\n",
      "2168\n",
      "2177\n",
      "2184\n",
      "2193\n",
      "2200\n",
      "2209\n",
      "2216\n",
      "2225\n",
      "s.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022232\n",
      "2241\n",
      "2248\n",
      "2257\n",
      "2264\n",
      "2273\n",
      "2280\n",
      "2289\n",
      "2296\n",
      "2305\n",
      "2312\n",
      "2321\n",
      "2328\n",
      "2337\n",
      "2344\n",
      "2353\n",
      "2360\n",
      "2369\n",
      "2376\n",
      "2385\n",
      "2392\n",
      "2401\n",
      "2408\n",
      "2417\n",
      "2424\n",
      "2433\n",
      "2-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [W] onnx2trt_utils.cpp:395: One or more weights outside the range of INT32 was clamped\n",
      "[07/26/2022-08:36:09] [TRT] [E] ImporterContext.cpp:93: Constant layer: 2056_1193 can be a duplicate of: 2056\n",
      "[07/26/2022-08:36:09] [TRT] [E] ImporterContext.cpp:93: Constant layer: 2037_1194 can be a dupl{'TopK': [1, ['2088']], 'NonZero': [98, ['811', '794', '750', '733', '689', '672', '628', '611', '567', '550', '2403', '2485', '2419', '2513', '2435', '2541', '2451', '2569', '6323', '6279', '6235', '6191', '6147', '6103', '6059', '6015', '5971', '5927', '5883', '5839', '5795', '5751', '5707', '5663', '5619', '5575', '5531', '5487', '5443', '5399', '5355', '5311', '5267', '5223', '5179', '5135', '5091', '5047', '5003', '4959', '4915', '4871', '4827', '4783', '4739', '4695', '4651', '4607', '4563', '4519', '4475', '4431', '4387', '4343', '4299', '4255', '4211', '4167', '4123', '4079', '4035', '3991', '3947', '3903', '3859', '3815', '3771', '3727', '3683', '3639', '3595', '3551', '3507', '3463', '3419', '3375', '3331', '3287', '3243', '3199', '3155', '3111', '3067', '3023', '2979', '2935', '2891', '2847']], 'NonMaxSuppression': [85, ['2311', '2016', '1721', '1426', '1131', '6342', '6298', '6254', '6210', '6166', '6122', '6078', '6034', '5990', '5946', '5902', '5858', '5814', '5770', '5726', '5682', '5638', '5594', '5550', '5506', '5462', '5418', '5374', '5330', '5286', '5242', '5198', '5154', '5110', '5066', '5022', '4978', '4934', '4890', '4846', '4802', '4758', '4714', '4670', '4626', '4582', '4538', '4494', '4450', '4406', '4362', '4318', '4274', '4230', '4186', '4142', '4098', '4054', '4010', '3966', '3922', '3878', '3834', '3790', '3746', '3702', '3658', '3614', '3570', '3526', '3482', '3438', '3394', '3350', '3306', '3262', '3218', '3174', '3130', '3086', '3042', '2998', '2954', '2910', '2866']], 'RoiAlign': [4, ['2414', '2430', '2446', '2462']]}\n",
      "icate of: 2037\n",
      "[07/26/2022-08:36:09] [TRT] [E] 4: [network.cpp::validate::2671] Error Code 4: Internal Error (Network must have at least one output)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1864/3206974603.py:84: DeprecationWarning: Use build_serialized_network instead.\n",
      "  return builder.build_engine(network, config=config)\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "\n",
    "tensorrt_file_name='jupyter_faster.trt'\n",
    "\n",
    "class ModelData(object):\n",
    "    MODEL_PATH = \"/data2/user/sjj995/TensorRT/temp2/FasterRCNN-12.onnx\"\n",
    "    INPUT_SHAPE = (1,3,224,224)\n",
    "    # We can convert TensorRT data types to numpy types with trt.nptype()\n",
    "    DTYPE = torch.float32\n",
    "\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "\n",
    "def GiB(val):\n",
    "    return val * 1 << 30\n",
    "    \n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "# The Onnx path is used for Onnx models.\n",
    "def build_engine_onnx(model_file):\n",
    "    \n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    profile = builder.create_optimization_profile()\n",
    "    #print(profile.get_shape_input())\n",
    "    #profile.set_shape(\"image_shape\", (1, 2),(1, 2),(1, 2))\n",
    "    #profile.set_shape(\"input_1\", (1,3, 416, 416),(1,3, 416, 416),(1,3, 416, 416))\n",
    "    profile.set_shape(\"data\", (1,3,224,224),(1,3,224,224),(1,3,224,224))\n",
    "    #print(profile.get_shape_input)\n",
    "    network = builder.create_network(EXPLICIT_BATCH)\n",
    "    \n",
    "    config = builder.create_builder_config()\n",
    "    config.add_optimization_profile(profile)\n",
    "    config.max_workspace_size = 8 << 30\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    parser_error = trt.ParserError\n",
    "    #Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "    \n",
    "    \n",
    "    \n",
    "    onnx_model_detailed = onnx.load(model_file)\n",
    "    print(len(onnx_model_detailed.graph.node))\n",
    "    \n",
    "    trt_support_node = []\n",
    "    unsupported_op = {}\n",
    "        \n",
    "    with open(model_file, \"rb\") as model:\n",
    "\n",
    "        chk_support = parser.supports_model(model.read())\n",
    "        print('여기2',parser.get_error(0).node())\n",
    "        for error in range(parser.num_errors):\n",
    "            print(error)\n",
    "            print('여기',parser.get_error(error).node())\n",
    "        \n",
    "        #print(chk_support)\n",
    "        for subgraph in chk_support[1]:\n",
    "            #print('subgraph',subgraph[0])\n",
    "            for idx in subgraph[0]:\n",
    "                #print(idx)\n",
    "                trt_support_node.append(idx)\n",
    "            #trt_support_node = subgraph[0]\n",
    "\n",
    "    for node_num,node_info in enumerate(onnx_model_detailed.graph.node):\n",
    "        if node_num not in trt_support_node:\n",
    "            #print(node_num,node_info.op_type)\n",
    "            print(node_num)\n",
    "            if node_info.op_type not in unsupported_op:\n",
    "                unsupported_op[node_info.op_type] = [1,[node_info.name]]\n",
    "            else:\n",
    "                unsupported_op[node_info.op_type][0] += 1\n",
    "                unsupported_op[node_info.op_type][1].append(node_info.name)\n",
    "#             unsupported_node_name[node_num] = node_info.name\n",
    "#             unsupported_op_type[node_num] = node_info.op_type\n",
    "    \n",
    "    print(unsupported_op)\n",
    "#     op_list = []\n",
    "#     for op in list(set(unsupported_op_type))[1:]:\n",
    "#         op_list.append(unsupported_op_type.count(op)\n",
    "    return builder.build_engine(network, config=config)\n",
    "\n",
    "onnx2 = ModelData()\n",
    "print(onnx2.MODEL_PATH)\n",
    "trt_engine = build_engine_onnx(onnx2.MODEL_PATH) # IcudaEngine \n",
    "print(trt_engine)\n",
    "\n",
    "# buf = trt_engine.serialize() # trt engine 으로  serialized\n",
    "# with open(tensorrt_file_name,'wb') as f:\n",
    "#     f.write(buf)\n",
    "\n",
    "# print(trt_engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
